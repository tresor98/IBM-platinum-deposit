{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>704</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>21</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>121</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>9</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>success</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>3115</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>432</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>149</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>29</td>\n",
       "      <td>507</td>\n",
       "      <td>3</td>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>140</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>15</td>\n",
       "      <td>760</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   35    management   single   tertiary      no      704      no   no   \n",
       "1   44  entrepreneur  married   tertiary      no      121      no   no   \n",
       "2   63    management  married   tertiary      no     3115      no   no   \n",
       "3   35   blue-collar  married  secondary      no      149     yes   no   \n",
       "4   30      services   single  secondary      no      140     yes   no   \n",
       "\n",
       "    contact  day  duration  campaign  pdays  previous poutcome    y  \n",
       "0  cellular   21       164         1     -1         0  unknown  yes  \n",
       "1  cellular    9       248         1     91         1  success  yes  \n",
       "2  cellular   16       432         5     -1         0  unknown  yes  \n",
       "3  cellular   29       507         3    349         1    other  yes  \n",
       "4  cellular   15       760         1     -1         0  unknown  yes  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_20319681.csv')\n",
    "#Getting rid of the column Unnamed: 0\n",
    "df1=df.loc[:,'age':'y']\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the target value to numeric\n",
    "df1.loc[df1['y']=='yes','y']=1\n",
    "df1.loc[df1['y']=='no','y']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>704</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>21</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>121</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>9</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>success</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>3115</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>432</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>149</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>29</td>\n",
       "      <td>507</td>\n",
       "      <td>3</td>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>140</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>15</td>\n",
       "      <td>760</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   35    management   single   tertiary      no      704      no   no   \n",
       "1   44  entrepreneur  married   tertiary      no      121      no   no   \n",
       "2   63    management  married   tertiary      no     3115      no   no   \n",
       "3   35   blue-collar  married  secondary      no      149     yes   no   \n",
       "4   30      services   single  secondary      no      140     yes   no   \n",
       "\n",
       "    contact  day  duration  campaign  pdays  previous poutcome  y  \n",
       "0  cellular   21       164         1     -1         0  unknown  1  \n",
       "1  cellular    9       248         1     91         1  success  1  \n",
       "2  cellular   16       432         5     -1         0  unknown  1  \n",
       "3  cellular   29       507         3    349         1    other  1  \n",
       "4  cellular   15       760         1     -1         0  unknown  1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing default feature\n",
    "df2 = df1.drop(columns='duration')\n",
    "df2 = df2.drop(columns='default')\n",
    "#df2 = df2.drop(columns='previous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>61</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>32685</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4350</th>\n",
       "      <td>50</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>57435</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>31</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>38279</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age         job  marital  education  balance housing loan   contact  \\\n",
       "288    61     retired  married   tertiary    32685      no   no  cellular   \n",
       "4350   50    services  married  secondary    57435     yes   no  cellular   \n",
       "4830   31  management   single   tertiary    38279      no   no  cellular   \n",
       "\n",
       "      day  campaign  pdays  previous poutcome  y  \n",
       "288     2         2     -1         0  unknown  1  \n",
       "4350   21         3     -1         0  unknown  0  \n",
       "4830   16         2     -1         0  unknown  0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['balance']>28000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing these outliers from balance\n",
    "df2 = df2.drop([288,4350,4830])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5997"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after get_dummies:  ['age', 'balance', 'day', 'campaign', 'pdays', 'previous', 'y', 'job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'job_unknown', 'marital_divorced', 'marital_married', 'marital_single', 'education_primary', 'education_secondary', 'education_tertiary', 'education_unknown', 'housing_no', 'housing_yes', 'loan_no', 'loan_yes', 'contact_cellular', 'contact_telephone', 'contact_unknown', 'poutcome_failure', 'poutcome_other', 'poutcome_success', 'poutcome_unknown']\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "#Changing our categorical variables to dummy variables\n",
    "df2_dummies = pd.get_dummies(df2)\n",
    "print('Features after get_dummies: ',list(df2_dummies.columns))\n",
    "print(len(list(df2_dummies.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split my data into data and target\n",
    "target = df2_dummies['y']\n",
    "data = df2_dummies.drop(columns='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Numpy arrays\n",
    "X = data\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5997, 36)\n",
      "(5997,)\n"
     ]
    }
   ],
   "source": [
    "#Print the shape of our data and target\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide our data into training set and testing set\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using function to select only some features.\n",
    "#We set the percentile of how many features we want to keep\n",
    "select = SelectPercentile(percentile=30)\n",
    "select.fit(X_train,y_train)\n",
    "#get_support can show you which features have been chosen and which have been not\n",
    "#select.get_support()\n",
    "X_train_selected = select.transform(X_train)\n",
    "X_test_selected = select.transform(X_test)\n",
    "\n",
    "#standardize our training data and testing data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_selected)\n",
    "X_train_scaled = scaler.transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix \n",
      "[[934 260]\n",
      " [241  65]]\n",
      "\n",
      "Logistic model classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79      1194\n",
      "           1       0.20      0.21      0.21       306\n",
      "\n",
      "    accuracy                           0.67      1500\n",
      "   macro avg       0.50      0.50      0.50      1500\n",
      "weighted avg       0.67      0.67      0.67      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using a model basedline \n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "#Train and test and display a confusion matrix\n",
    "dummy = dummy_clf.fit(X_train_scaled,y_train)\n",
    "pred = dummy.predict(X_test_scaled)\n",
    "print('Confusion matrix ')\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print()\n",
    "#print a classification report that includes precision,recall and F-1\n",
    "print('Logistic model classification report')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using stratified k-fold cross validation\n",
    "kfold = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores from the cross validation  [0.82888889 0.83777778 0.80666667 0.79111111 0.82       0.81777778\n",
      " 0.81555556 0.82405345 0.83518931 0.81514477]\n",
      "Average cross validation score on logistic regression is  0.8192165305617423\n",
      "Score on test set:  0.8166666666666667\n",
      "Confusion matrix \n",
      "[[1177   17]\n",
      " [ 258   48]]\n",
      "\n",
      "Logistic model classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90      1194\n",
      "           1       0.74      0.16      0.26       306\n",
      "\n",
      "    accuracy                           0.82      1500\n",
      "   macro avg       0.78      0.57      0.58      1500\n",
      "weighted avg       0.80      0.82      0.77      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using our stratified cross validation on our three models and displaying the averages scores\n",
    "#First we start with our logistic regression\n",
    "# We will use score(which uses accuracy) and we will deploy other evaluation metrics such as confusion matrices \n",
    "#and performances metrics such as precision, recall and F-1\n",
    "\n",
    "logreg = LogisticRegression(C=200)\n",
    "scores = cross_val_score(logreg,X_train_scaled,y_train,cv=kfold)\n",
    "print('Scores from the cross validation ', scores)\n",
    "print('Average cross validation score on logistic regression is ',scores.mean())\n",
    "\n",
    "#Train and test and display a confusion matrix\n",
    "logreg1 = logreg.fit(X_train_scaled,y_train)\n",
    "pred = logreg1.predict(X_test_scaled)\n",
    "print('Score on test set: ', logreg1.score(X_test_scaled,y_test))\n",
    "print('Confusion matrix ')\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print()\n",
    "#print a classification report that includes precision,recall and F-1\n",
    "print('Logistic model classification report')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores from the decision tree  [0.82222222 0.81555556 0.80444444 0.77777778 0.81777778 0.80888889\n",
      " 0.82       0.81959911 0.81959911 0.81514477]\n",
      "Average validation score on decision tree is  0.8121009651076466\n",
      "Training and testing \n",
      "Score on test set:  0.818\n",
      "Confusion matrix \n",
      "[[1180   14]\n",
      " [ 259   47]]\n",
      "\n",
      "Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90      1194\n",
      "           1       0.77      0.15      0.26       306\n",
      "\n",
      "    accuracy                           0.82      1500\n",
      "   macro avg       0.80      0.57      0.58      1500\n",
      "weighted avg       0.81      0.82      0.77      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision tree\n",
    "#Applying cross validation\n",
    "tree = DecisionTreeClassifier(max_depth=7, random_state=0)\n",
    "scores = cross_val_score(tree,X_train_scaled,y_train,cv=kfold)\n",
    "print('Scores from the decision tree ', scores)\n",
    "print('Average validation score on decision tree is ',scores.mean())\n",
    "#Training on the training set and testing on the testing set\n",
    "#Display confusion matrix and classification report\n",
    "print('Training and testing ')\n",
    "tree1 = tree.fit(X_train_scaled,y_train)\n",
    "pred_tree = tree1.predict(X_test_scaled)\n",
    "print('Score on test set: ',tree1.score(X_test_scaled,y_test))\n",
    "print('Confusion matrix ')\n",
    "print(confusion_matrix(y_test,pred_tree))\n",
    "print()\n",
    "print('Classification report ')\n",
    "print(classification_report(y_test,pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores from the decision tree  [0.81333333 0.81555556 0.79555556 0.78666667 0.82888889 0.81111111\n",
      " 0.80888889 0.81737194 0.83296214 0.79287305]\n",
      "Average cross validation score on random forest is  0.8103207126948775\n",
      "Training and testing \n",
      "Score on test set:  0.814\n",
      "Confusion matrix \n",
      "[[1163   31]\n",
      " [ 248   58]]\n",
      "\n",
      "Classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      1194\n",
      "           1       0.65      0.19      0.29       306\n",
      "\n",
      "    accuracy                           0.81      1500\n",
      "   macro avg       0.74      0.58      0.59      1500\n",
      "weighted avg       0.79      0.81      0.77      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random forest\n",
    "forest = RandomForestClassifier(n_estimators = 40,random_state =2)\n",
    "scores = cross_val_score(forest,X_train_scaled,y_train,cv=kfold)\n",
    "print('Scores from the decision tree ', scores)\n",
    "print('Average cross validation score on random forest is ',scores.mean())\n",
    "#Training on the training set and testing on the testing set\n",
    "#Display confusion matrix and classification report\n",
    "print('Training and testing ')\n",
    "forest1 = forest.fit(X_train_scaled,y_train)\n",
    "pred_forest = forest1.predict(X_test_scaled)\n",
    "print('Score on test set: ',forest1.score(X_test_scaled,y_test))\n",
    "print('Confusion matrix ')\n",
    "print(confusion_matrix(y_test,pred_forest))\n",
    "print()\n",
    "print('Classification report ')\n",
    "print(classification_report(y_test,pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to automate the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automating the training process for checking best parameters for logistic regression\n",
    "def tuning_best_model_param(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    #Getting rid of the column Unnamed: 0\n",
    "    df1=df.loc[:,'age':'y']\n",
    "    #Converting the target value to numeric\n",
    "    df1.loc[df1['y']=='yes','y']=1\n",
    "    df1.loc[df1['y']=='no','y']=0\n",
    "    #Removing default feature\n",
    "    df2 = df1.drop(columns='duration')\n",
    "    df2 = df2.drop(columns='default')\n",
    "    #Drop the columns with balance over 28000\n",
    "    df2 = df2[df2['balance']<28000]\n",
    "    #Apply get dummies on categorical variable\n",
    "    #print('Features before get_dummies: ')\n",
    "    #print(list(df2.columns))\n",
    "    df2_dummies = pd.get_dummies(df2)\n",
    "    #print('Features after get_dummies: ')\n",
    "    #print(list(df2_dummies.columns))\n",
    "    #print(len(list(df2_dummies.columns)))\n",
    "    #split my data into data and target\n",
    "    target = df2_dummies['y']\n",
    "    data = df2_dummies.drop(columns='y')\n",
    "    #Extract Numpy arrays\n",
    "    X = data.values\n",
    "    y = target.values\n",
    "    #Print the shape of our data and target\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    #Divide our data into training set and testing set\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)\n",
    "    #Trying many parameters\n",
    "    percent = [100,80,70,60,50,40,30]\n",
    "    param = [0.01,0.05,0.1,0.5,1,10,50,100,200]\n",
    "    max_precision = 0.69\n",
    "    min_FP = 25\n",
    "    max_TP = 40\n",
    "    #best_cross_val = 0.82\n",
    "    best_percent = 50\n",
    "    best_param = 100\n",
    "    #best_score_test = 0.82\n",
    "    for i in percent:\n",
    "        for j in param:\n",
    "            #Using select percentile\n",
    "            select = SelectPercentile(percentile=i)\n",
    "            select.fit(X_train,y_train)\n",
    "            X_train_selected = select.transform(X_train)\n",
    "            X_test_selected = select.transform(X_test)\n",
    "            #standardize our training data and testing data\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train_selected)\n",
    "            X_train_scaled = scaler.transform(X_train_selected)\n",
    "            X_test_scaled = scaler.transform(X_test_selected)\n",
    "    \n",
    "            kfold = KFold(n_splits=10) \n",
    "            logreg = LogisticRegression(C=j)\n",
    "            scores = cross_val_score(logreg,X_train_scaled,y_train,cv=kfold)\n",
    "            \n",
    "            logreg1 = logreg.fit(X_train_scaled,y_train)\n",
    "            pred = logreg1.predict(X_test_scaled)\n",
    "            score_test = logreg1.score(X_test_scaled,y_test)\n",
    "            FP = confusion_matrix(y_test,pred)[0][1]\n",
    "            TP = confusion_matrix(y_test,pred)[1][1]\n",
    "            precision = float(classification_report(y_test,pred)[128:132])\n",
    "            if  FP <= min_FP :\n",
    "                min_FP = confusion_matrix(y_test,pred)[0][1]\n",
    "                max_TP = confusion_matrix(y_test,pred)[1][1]\n",
    "                #best_cross_val = scores.mean()\n",
    "                #best_score_test = score_test\n",
    "                max_precision = precision\n",
    "                best_percent = i\n",
    "                best_param = j\n",
    "    print('Min FP is : ',min_FP)\n",
    "    print('Max TP is : ',max_TP)\n",
    "    print('Max precision is ', max_precision)\n",
    "    print(\"Percent is \",best_percent)\n",
    "    print('Param is ',best_param)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min FP is :  17\n",
      "Max TP is :  48\n",
      "Max precision is  0.74\n",
      "Percent is  30\n",
      "Param is  200\n"
     ]
    }
   ],
   "source": [
    "tuning_best_model_param('data_20319681.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automating the training process for decision tree\n",
    "def tuning_best_model_param_dt(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    #Getting rid of the column Unnamed: 0\n",
    "    df1=df.loc[:,'age':'y']\n",
    "    #Converting the target value to numeric\n",
    "    df1.loc[df1['y']=='yes','y']=1\n",
    "    df1.loc[df1['y']=='no','y']=0\n",
    "    #Removing default feature\n",
    "    df2 = df1.drop(columns='duration')\n",
    "    df2 = df2.drop(columns='default')\n",
    "    #Drop the columns with balance over 28000\n",
    "    df2 = df2[df2['balance']<28000]\n",
    "    #Apply get dummies on categorical variable\n",
    "    #print('Features before get_dummies: ')\n",
    "    #print(list(df2.columns))\n",
    "    df2_dummies = pd.get_dummies(df2)\n",
    "    #print('Features after get_dummies: ')\n",
    "    #print(list(df2_dummies.columns))\n",
    "    #print(len(list(df2_dummies.columns)))\n",
    "    #split my data into data and target\n",
    "    target = df2_dummies['y']\n",
    "    data = df2_dummies.drop(columns='y')\n",
    "    #Extract Numpy arrays\n",
    "    X = data.values\n",
    "    y = target.values\n",
    "    #Print the shape of our data and target\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    #Divide our data into training set and testing set\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)\n",
    "    #Trying many parameters\n",
    "    percent = [80,70,60,50,40,30]\n",
    "    param = [2,3,4,5,6,7,8]\n",
    "    max_precision = 0.69\n",
    "    min_FP = 25\n",
    "    max_TP = 40\n",
    "    #best_cross_val = 0.82\n",
    "    best_percent = 80\n",
    "    best_param = 4\n",
    "    #best_score_test = 0.82\n",
    "    for i in percent:\n",
    "        for j in param:\n",
    "            #Using select percentile\n",
    "            select = SelectPercentile(percentile=i)\n",
    "            select.fit(X_train,y_train)\n",
    "            X_train_selected = select.transform(X_train)\n",
    "            X_test_selected = select.transform(X_test)\n",
    "            #standardize our training data and testing data\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train_selected)\n",
    "            X_train_scaled = scaler.transform(X_train_selected)\n",
    "            X_test_scaled = scaler.transform(X_test_selected)\n",
    "    \n",
    "            kfold = KFold(n_splits=10) \n",
    "            tree = DecisionTreeClassifier(max_depth=j, random_state=0)\n",
    "            scores = cross_val_score(tree,X_train_scaled,y_train,cv=kfold)\n",
    "            \n",
    "            tree1 = tree.fit(X_train_scaled,y_train)\n",
    "            pred = tree1.predict(X_test_scaled)\n",
    "            score_test = tree1.score(X_test_scaled,y_test)\n",
    "            FP = confusion_matrix(y_test,pred)[0][1]\n",
    "            TP = confusion_matrix(y_test,pred)[1][1]\n",
    "            precision = float(classification_report(y_test,pred)[128:132])\n",
    "            if  FP <= min_FP :\n",
    "                min_FP = confusion_matrix(y_test,pred)[0][1]\n",
    "                max_TP = confusion_matrix(y_test,pred)[1][1]\n",
    "                #best_cross_val = scores.mean()\n",
    "                #best_score_test = score_test\n",
    "                max_precision = precision\n",
    "                best_percent = i\n",
    "                best_param = j\n",
    "    print('Min FP is : ',min_FP)\n",
    "    print('Max TP is : ',max_TP)\n",
    "    print('Max precision is ', max_precision)\n",
    "    print(\"Percent is \",best_percent)\n",
    "    print('Param is ',best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min FP is :  14\n",
      "Max TP is :  47\n",
      "Max precision is  0.77\n",
      "Percent is  30\n",
      "Param is  7\n"
     ]
    }
   ],
   "source": [
    "tuning_best_model_param_dt('data_20319681.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automating the training process for decision tree\n",
    "def tuning_best_model_param_rf(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    #Getting rid of the column Unnamed: 0\n",
    "    df1=df.loc[:,'age':'y']\n",
    "    #Converting the target value to numeric\n",
    "    df1.loc[df1['y']=='yes','y']=1\n",
    "    df1.loc[df1['y']=='no','y']=0\n",
    "    #Removing default feature\n",
    "    df2 = df1.drop(columns='duration')\n",
    "    df2 = df2.drop(columns='default')\n",
    "    #Drop the columns with balance over 28000\n",
    "    df2 = df2[df2['balance']<28000]\n",
    "    #Apply get dummies on categorical variable\n",
    "    #print('Features before get_dummies: ')\n",
    "    #print(list(df2.columns))\n",
    "    df2_dummies = pd.get_dummies(df2)\n",
    "    #print('Features after get_dummies: ')\n",
    "    #print(list(df2_dummies.columns))\n",
    "    #print(len(list(df2_dummies.columns)))\n",
    "    #split my data into data and target\n",
    "    target = df2_dummies['y']\n",
    "    data = df2_dummies.drop(columns='y')\n",
    "    #Extract Numpy arrays\n",
    "    X = data.values\n",
    "    y = target.values\n",
    "    #Print the shape of our data and target\n",
    "    #print(X.shape)\n",
    "    #print(y.shape)\n",
    "    #Divide our data into training set and testing set\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)\n",
    "    #Trying many parameters\n",
    "    percent = [100,80,70,60,50,40,30]\n",
    "    param = [10,20,40,50,60,100,150,200]\n",
    "    max_precision = 0.69\n",
    "    min_FP = 40\n",
    "    max_TP = 30\n",
    "    #best_cross_val = 0.82\n",
    "    best_percent = 100\n",
    "    best_param = 10\n",
    "    #best_score_test = 0.82\n",
    "    for i in percent:\n",
    "        for j in param:\n",
    "            #Using select percentile\n",
    "            select = SelectPercentile(percentile=i)\n",
    "            select.fit(X_train,y_train)\n",
    "            X_train_selected = select.transform(X_train)\n",
    "            X_test_selected = select.transform(X_test)\n",
    "            #standardize our training data and testing data\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X_train_selected)\n",
    "            X_train_scaled = scaler.transform(X_train_selected)\n",
    "            X_test_scaled = scaler.transform(X_test_selected)\n",
    "    \n",
    "            kfold = KFold(n_splits=10) \n",
    "            forest = RandomForestClassifier(n_estimators = j,random_state =2)\n",
    "            scores = cross_val_score(forest,X_train_scaled,y_train,cv=kfold)\n",
    "            \n",
    "            forest1 = forest.fit(X_train_scaled,y_train)\n",
    "            pred = forest1.predict(X_test_scaled)\n",
    "            score_test = forest1.score(X_test_scaled,y_test)\n",
    "            FP = confusion_matrix(y_test,pred)[0][1]\n",
    "            TP = confusion_matrix(y_test,pred)[1][1]\n",
    "            precision = float(classification_report(y_test,pred)[128:132])\n",
    "            if  FP <= min_FP :\n",
    "                min_FP = confusion_matrix(y_test,pred)[0][1]\n",
    "                max_TP = confusion_matrix(y_test,pred)[1][1]\n",
    "                #best_cross_val = scores.mean()\n",
    "                #best_score_test = score_test\n",
    "                max_precision = precision\n",
    "                best_percent = i\n",
    "                best_param = j\n",
    "    print('Min FP is : ',min_FP)\n",
    "    print('Max TP is : ',max_TP)\n",
    "    print('Max precision is ', max_precision)\n",
    "    print(\"Percent is \",best_percent)\n",
    "    print('Param is ',best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min FP is :  31\n",
      "Max TP is :  58\n",
      "Max precision is  0.65\n",
      "Percent is  30\n",
      "Param is  40\n"
     ]
    }
   ],
   "source": [
    "tuning_best_model_param_rf('data_20319681.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
